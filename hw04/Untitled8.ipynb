{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IXxvVSADT1vv"
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.pipeline import Pipeline, make_pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import FunctionTransformer, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.stem import PorterStemmer \n",
    "from nltk import word_tokenize \n",
    "from nltk.util import ngrams\n",
    "import re, string\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "gN3CPnuDWSiR",
    "outputId": "04f77e47-24c3-45bf-f019-a56b63be889c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "SzdqCNtrPStV",
    "outputId": "073a661a-2269-4024-c6f0-c2d15494e6d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dsLmxMb7T2aA"
   },
   "outputs": [],
   "source": [
    "def readGz(path):\n",
    "    for l in gzip.open(path, 'rt'):\n",
    "        yield eval(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ddQPYkFWTiER"
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for d in readGz(\"drive/My Drive/cse 158/assignment1/train_Category.json.gz\"):\n",
    "    data.append(d)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "faZePHmKG0hU",
    "outputId": "dcac5229-b3a0-49fc-8fac-f0a41f0e0861"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_votes</th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>review_text</th>\n",
       "      <th>rating</th>\n",
       "      <th>genreID</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>r99763621</td>\n",
       "      <td>u17334941</td>\n",
       "      <td>Genuinely enthralling. If Collins or Bernard d...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>fantasy_paranormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>r24440074</td>\n",
       "      <td>u08070901</td>\n",
       "      <td>Pretty decent. The ending seemed a little rush...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>fantasy_paranormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>r82777443</td>\n",
       "      <td>u36921467</td>\n",
       "      <td>Philippa created an intricate world composed o...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>fantasy_paranormal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>r05772772</td>\n",
       "      <td>u07405640</td>\n",
       "      <td>A very light, good, quirky read. I felt like I...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>mystery_thriller_crime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>r33622824</td>\n",
       "      <td>u10191516</td>\n",
       "      <td>It was a Christmas gift from a friend, how kno...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>fantasy_paranormal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_votes  review_id    user_id  ... rating  genreID                   genre\n",
       "0        0  r99763621  u17334941  ...      5        2      fantasy_paranormal\n",
       "1        0  r24440074  u08070901  ...      5        2      fantasy_paranormal\n",
       "2        0  r82777443  u36921467  ...      4        2      fantasy_paranormal\n",
       "3        0  r05772772  u07405640  ...      5        3  mystery_thriller_crime\n",
       "4        0  r33622824  u10191516  ...      5        2      fantasy_paranormal\n",
       "\n",
       "[5 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "ohwS3qNcT9zM",
    "outputId": "bd59717c-65ec-450b-b004-9df5159321b6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Genuinely enthralling. If Collins or Bernard d...\n",
       "1    Pretty decent. The ending seemed a little rush...\n",
       "2    Philippa created an intricate world composed o...\n",
       "3    A very light, good, quirky read. I felt like I...\n",
       "4    It was a Christmas gift from a friend, how kno...\n",
       "Name: review_text, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_text = df['review_text'].copy(deep=True).iloc[:10000]\n",
    "review_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IO8MsaMVUD3k"
   },
   "outputs": [],
   "source": [
    "review_text = review_text.apply(lambda doc: re.sub('[%s]' % re.escape(string.punctuation), '', doc.lower()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "65GueRLPT4GA"
   },
   "source": [
    "# Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "iRVCrBIrVEJ7",
    "outputId": "4b100c55-8471-4007-e16d-c85df4406f8e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       genuinely enthralling if collins or bernard di...\n",
       "1       pretty decent the ending seemed a little rush ...\n",
       "2       philippa created an intricate world composed o...\n",
       "3       a very light good quirky read i felt like i wa...\n",
       "4       it was a christmas gift from a friend how know...\n",
       "                              ...                        \n",
       "9995    as posted on kindleobsessed blog \\n well ladie...\n",
       "9996    rating 4 out of 5 stars  \\n friendship murder ...\n",
       "9997    very great main character  paddy i really like...\n",
       "9998    loved it loved it loved it \\n although the end...\n",
       "9999    im not really sure how to review this book and...\n",
       "Name: review_text, Length: 10000, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams_dict = {}\n",
    "def save_bigrams(doc):\n",
    "  token = word_tokenize(doc)\n",
    "  bigram_list = list(ngrams(token, 2)) \n",
    "  for bigram in bigram_list:\n",
    "    if bigram not in bigrams_dict:\n",
    "      bigrams_dict[bigram] = 0\n",
    "    bigrams_dict[bigram] += 1\n",
    "  return doc\n",
    "review_text.apply(save_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZAHeVe9RaYww"
   },
   "outputs": [],
   "source": [
    "bigrams_freq_list = [(k, v) for k, v in bigrams_dict.items()]\n",
    "del bigrams_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D1eEuC_AXtC1"
   },
   "outputs": [],
   "source": [
    "bigrams_freq_list.sort(key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "kioviWhOb6pi",
    "outputId": "5a41fb55-e933-43e2-f3ef-f65223ae2a16"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('of', 'the'), 7927),\n",
       " (('this', 'book'), 5850),\n",
       " (('in', 'the'), 5627),\n",
       " (('and', 'the'), 3189),\n",
       " (('is', 'a'), 3183)]"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams_freq_list[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dUyauK6HabBn"
   },
   "source": [
    "Answer to Q1:\n",
    "\n",
    "(Format = Bigrams : Freq)\n",
    "\n",
    "1.   ('of', 'the'): 7927\n",
    "2.   ('this', 'book'): 5850\n",
    "3.   ('in', 'the'): 5627\n",
    "4.   ('and', 'the'): 3189\n",
    "5.   ('the', 'book'): 3183"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SmaeuOziTzuc"
   },
   "source": [
    "# Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ONHRievMb7wz"
   },
   "outputs": [],
   "source": [
    "top_1000_bigrams = [bigram_pair[0] for bigram_pair in bigrams_freq_list[:1000]]\n",
    "bigram_index_dict = {bigram: i for i, bigram in enumerate(top_1000_bigrams)}\n",
    "del bigrams_freq_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gGDJiqPcEov4"
   },
   "outputs": [],
   "source": [
    "def top_1000_bigrams_feat(doc):\n",
    "  token = word_tokenize(doc)\n",
    "  bigram_list = list(ngrams(token, 2))\n",
    "  bigram_feat = [0] * len(bigram_index_dict)\n",
    "  for bigram in bigram_list:\n",
    "    if bigram in bigram_index_dict:\n",
    "      bigram_feat[bigram_index_dict[bigram]] += 1\n",
    "  bigram_feat.append(1)\n",
    "  return bigram_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8ZsEZCE2GvFf"
   },
   "outputs": [],
   "source": [
    "X_q2 = review_text.apply(top_1000_bigrams_feat)\n",
    "X_q2 = X_q2.apply(lambda x: pd.Series(x))\n",
    "y_rating = df['rating'].iloc[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7pzX-Fi0Fyp-"
   },
   "outputs": [],
   "source": [
    "clf = linear_model.Ridge(1.0, fit_intercept=False) # MSE + 1.0 l2\n",
    "clf.fit(X_q2, y_rating)\n",
    "theta = clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LUXKBry4HyPb"
   },
   "outputs": [],
   "source": [
    "def MSE(X, theta, y):\n",
    "    res = np.matrix(X)*np.matrix(theta).T - np.matrix(y).T\n",
    "    sq = np.array(res)**2\n",
    "    MSE = sum(sq) / len(sq)\n",
    "    return MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "GSIiaF8cH0zS",
    "outputId": "8d37b23f-8221-485e-affa-e35bb9bfb360"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.01806278])"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE(X_q2, theta, y_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GB9HSxa0U9pP"
   },
   "outputs": [],
   "source": [
    "del X_q2\n",
    "del clf\n",
    "del theta\n",
    "del y_rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2FKZwqCCR53h"
   },
   "source": [
    "Answer to Q2:\n",
    "\n",
    "MSE = 1.01806278"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9WIuI9C7TwaD"
   },
   "source": [
    "# Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "yLrCnYXAMfKz",
    "outputId": "b2ed01cb-7118-4a82-d095-ead31c2a48c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       genuinely enthralling if collins or bernard di...\n",
       "1       pretty decent the ending seemed a little rush ...\n",
       "2       philippa created an intricate world composed o...\n",
       "3       a very light good quirky read i felt like i wa...\n",
       "4       it was a christmas gift from a friend how know...\n",
       "                              ...                        \n",
       "9995    as posted on kindleobsessed blog \\n well ladie...\n",
       "9996    rating 4 out of 5 stars  \\n friendship murder ...\n",
       "9997    very great main character  paddy i really like...\n",
       "9998    loved it loved it loved it \\n although the end...\n",
       "9999    im not really sure how to review this book and...\n",
       "Name: review_text, Length: 10000, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigrams_dict = {}\n",
    "def save_unigrams(doc):\n",
    "  unigram_list = word_tokenize(doc)\n",
    "  for unigram in unigram_list:\n",
    "    if unigram not in unigrams_dict:\n",
    "      unigrams_dict[unigram] = 0\n",
    "    unigrams_dict[unigram] += 1\n",
    "  return doc\n",
    "review_text.apply(save_unigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uDPGiIPaMx-8"
   },
   "outputs": [],
   "source": [
    "unigrams_freq_list = [(k, v) for k, v in unigrams_dict.items()]\n",
    "unigrams_freq_list.sort(key=lambda x: x[1], reverse=True)\n",
    "del unigrams_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2018oMTrM6Kx"
   },
   "outputs": [],
   "source": [
    "top_1000_uni_bigram = [unigram_pair[0] for unigram_pair in unigrams_freq_list[:400]] + \\\n",
    "                      top_1000_bigrams[:600]\n",
    "uni_bigram_index_dict = {curr_gram: i for i, curr_gram in enumerate(top_1000_uni_bigram)}\n",
    "del unigrams_freq_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lwXiFihlMV_c"
   },
   "outputs": [],
   "source": [
    "def top_1000_uni_bigrams_feat(doc):\n",
    "  token = word_tokenize(doc)\n",
    "  bigram_list = list(ngrams(token, 2))\n",
    "  uni_bigram_feat = [0] * len(top_1000_bigrams)\n",
    "  for bigram in bigram_list:\n",
    "    if bigram in uni_bigram_index_dict:\n",
    "      uni_bigram_feat[uni_bigram_index_dict[bigram]] += 1\n",
    "  for unigram in token:\n",
    "    if unigram in uni_bigram_index_dict:\n",
    "      uni_bigram_feat[uni_bigram_index_dict[unigram]] += 1\n",
    "  uni_bigram_feat.append(1)\n",
    "  return uni_bigram_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L2aNmB9hOnoL"
   },
   "outputs": [],
   "source": [
    "X_q3 = review_text.apply(top_1000_uni_bigrams_feat)\n",
    "X_q3 = X_q3.apply(lambda x: pd.Series(x))\n",
    "y_rating = df['rating'].iloc[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zYT1MD_IOt2z"
   },
   "outputs": [],
   "source": [
    "clf = linear_model.Ridge(1.0, fit_intercept=False) # MSE + 1.0 l2\n",
    "clf.fit(X_q3, y_rating)\n",
    "theta = clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "V1JRY2ytOwcV",
    "outputId": "fc94f917-e0a4-49a2-e311-8ade26cab54f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.98249739])"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE(X_q3, theta, y_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w6_f22dpXs5n"
   },
   "outputs": [],
   "source": [
    "del X_q3\n",
    "del clf\n",
    "del theta\n",
    "del y_rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E5JjGmcDT9Hl"
   },
   "source": [
    "Answer to Q3:\n",
    "\n",
    "MSE = 0.98249739"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pfVok56NZDFT"
   },
   "source": [
    "# Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sd0QI3wlT0d9"
   },
   "outputs": [],
   "source": [
    "idf_words_q4 = {'stories': 0,\n",
    "                'magician': 0,\n",
    "                'psychic': 0,\n",
    "                'writing': 0,\n",
    "                'wonder': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "-3J5LAb_TzII",
    "outputId": "58e4f62c-adab-4e58-96f5-01ed18da7235"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       genuinely enthralling if collins or bernard di...\n",
       "1       pretty decent the ending seemed a little rush ...\n",
       "2       philippa created an intricate world composed o...\n",
       "3       a very light good quirky read i felt like i wa...\n",
       "4       it was a christmas gift from a friend how know...\n",
       "                              ...                        \n",
       "9995    as posted on kindleobsessed blog \\n well ladie...\n",
       "9996    rating 4 out of 5 stars  \\n friendship murder ...\n",
       "9997    very great main character  paddy i really like...\n",
       "9998    loved it loved it loved it \\n although the end...\n",
       "9999    im not really sure how to review this book and...\n",
       "Name: review_text, Length: 10000, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def save_idf_counter(doc):\n",
    "  token_set = set(word_tokenize(doc))\n",
    "  for curr_word in idf_words_q4.keys():\n",
    "    if curr_word in token_set:\n",
    "      idf_words_q4[curr_word] += 1\n",
    "  return doc\n",
    "review_text.apply(save_idf_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "7YqeUm3QZvuv",
    "outputId": "28310098-de3a-49a7-e02c-a95ba9476df4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stories : 1.1174754620451195\n",
      "magician : 2.6575773191777934\n",
      "psychic : 2.602059991327962\n",
      "writing : 0.9978339382434922\n",
      "wonder : 1.7670038896078457\n"
     ]
    }
   ],
   "source": [
    "for k, v in idf_words_q4.items():\n",
    "  print(k,':', math.log(review_text.shape[0] / v, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2BtjqaHAfB-L"
   },
   "outputs": [],
   "source": [
    "tf_words_q4 = {'stories': 0,\n",
    "               'magician': 0,\n",
    "               'psychic': 0,\n",
    "               'writing': 0,\n",
    "               'wonder': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fJtmfepJfMqb"
   },
   "outputs": [],
   "source": [
    "for curr_word in review_text[0].split():\n",
    "  if curr_word in tf_words_q4:\n",
    "    tf_words_q4[curr_word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "vq7y5_x5fZFa",
    "outputId": "921257d0-d5a0-4584-ab4a-07b59185c1f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stories 0.0010318332982872755\n",
      "magician 0.00245390334180775\n",
      "psychic 0.004805281609100576\n",
      "writing 0.0009213609771408053\n",
      "wonder 0.001631582538880744\n"
     ]
    }
   ],
   "source": [
    "for k, v in tf_words_q4.items():\n",
    "  print(k, v / len(review_text[0]) *\n",
    "          math.log(review_text.shape[0] / idf_words_q4[k],\n",
    "                   10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p7gDDd6tafVN"
   },
   "source": [
    "Answer to Q4:\n",
    "\n",
    "(Format = word : idf-score through log base 10)\n",
    "\n",
    "1. stories : 1.1174754620451195\n",
    "2. magician : 2.6575773191777934\n",
    "3. psychic : 2.602059991327962\n",
    "4. writing : 0.9978339382434922\n",
    "5. wonder : 1.7670038896078457\n",
    "\n",
    "(Format = word : tfidf-score through log base 10)\n",
    "\n",
    "1. stories : 0.0010318332982872755\n",
    "2. magician : 0.00245390334180775\n",
    "3. psychic : 0.004805281609100576\n",
    "4. writing : 0.0009213609771408053\n",
    "5. wonder : 0.001631582538880744"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qK_jD9n4m_J4"
   },
   "source": [
    "# Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sM8YQmFbchWi"
   },
   "outputs": [],
   "source": [
    "unigrams_dict = {}\n",
    "def save_unigrams(doc):\n",
    "  unigram_list = word_tokenize(doc)\n",
    "  for unigram in unigram_list:\n",
    "    if unigram not in unigrams_dict:\n",
    "      unigrams_dict[unigram] = 0\n",
    "    unigrams_dict[unigram] += 1\n",
    "  return doc\n",
    "review_text.apply(save_unigrams)\n",
    "\n",
    "unigrams_freq_list = [(k, v) for k, v in unigrams_dict.items()]\n",
    "unigrams_freq_list.sort(key=lambda x: x[1], reverse=True)\n",
    "del unigrams_dict\n",
    "\n",
    "top_1000_unigrams = [unigram_pair[0] for unigram_pair in unigrams_freq_list[:1000]]\n",
    "unigram_index_dict = {curr_gram: i for i, curr_gram in enumerate(top_1000_unigrams)}\n",
    "unigram_idf_dict = {curr_gram: 0 for curr_gram in top_1000_unigrams}\n",
    "del unigrams_freq_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "4dkhyihykedk",
    "outputId": "cbc70157-8c4c-459e-8dcc-f500bdaad8da"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       genuinely enthralling if collins or bernard di...\n",
       "1       pretty decent the ending seemed a little rush ...\n",
       "2       philippa created an intricate world composed o...\n",
       "3       a very light good quirky read i felt like i wa...\n",
       "4       it was a christmas gift from a friend how know...\n",
       "                              ...                        \n",
       "9995    as posted on kindleobsessed blog \\n well ladie...\n",
       "9996    rating 4 out of 5 stars  \\n friendship murder ...\n",
       "9997    very great main character  paddy i really like...\n",
       "9998    loved it loved it loved it \\n although the end...\n",
       "9999    im not really sure how to review this book and...\n",
       "Name: review_text, Length: 10000, dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def save_q5_idf_counter(doc):\n",
    "  token_set = set(word_tokenize(doc))\n",
    "  for curr_word in token_set:\n",
    "    if curr_word in unigram_idf_dict:\n",
    "      unigram_idf_dict[curr_word] += 1\n",
    "  return doc\n",
    "review_text.apply(save_q5_idf_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MwPlQgSbjYGc"
   },
   "outputs": [],
   "source": [
    "def top_1000_tfidf_feat(doc):\n",
    "  token = word_tokenize(doc)\n",
    "  unigram_feat = [0] * len(top_1000_unigrams)\n",
    "  for unigram in token:\n",
    "    if unigram in unigram_index_dict:\n",
    "      unigram_feat[unigram_index_dict[unigram]] += 1\n",
    "  for unigram in set(token):\n",
    "    if unigram in unigram_index_dict:\n",
    "      unigram_feat[unigram_index_dict[unigram]] /= len(token)\n",
    "      unigram_feat[unigram_index_dict[unigram]] *=\\\n",
    "        math.log(review_text.shape[0] / unigram_idf_dict[unigram],\n",
    "                   10)\n",
    "  \n",
    "  unigram_feat.append(1)\n",
    "  return unigram_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zgorcRHFl9dI"
   },
   "outputs": [],
   "source": [
    "X_q5 = review_text.apply(top_1000_tfidf_feat)\n",
    "X_q5 = X_q5.apply(lambda x: pd.Series(x))\n",
    "y_rating = df['rating'].iloc[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e6NR_K-nmG7D"
   },
   "outputs": [],
   "source": [
    "clf = linear_model.Ridge(1.0, fit_intercept=False) # MSE + 1.0 l2\n",
    "clf.fit(X_q5, y_rating)\n",
    "theta = clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "mhsdHTA5mS20",
    "outputId": "7c74ced3-ac74-4ca9-ab0e-ca79124a48a3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.17836625])"
      ]
     },
     "execution_count": 52,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE(X_q5, theta, y_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oCYRjA88mTOc"
   },
   "outputs": [],
   "source": [
    "del y_rating\n",
    "del unigram_idf_dict\n",
    "del unigram_index_dict\n",
    "del top_1000_unigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v9P4J9n6mkyL"
   },
   "source": [
    "Answer to Q5:\n",
    "\n",
    "MSE = 1.17836625"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b7KXsmt7n44t"
   },
   "source": [
    "# Q6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kXlPJw88pJzJ"
   },
   "outputs": [],
   "source": [
    "def cos_sim(a, b):\n",
    "\tdot_product = np.dot(a, b)\n",
    "\tnorm_a = np.linalg.norm(a)\n",
    "\tnorm_b = np.linalg.norm(b)\n",
    "\treturn dot_product / (norm_a * norm_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 836
    },
    "colab_type": "code",
    "id": "7VJku8jeme8k",
    "outputId": "63dccf03-661f-4012-ce3b-d5120a2a8d19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9984838370882461\n",
      "Int64Index([1595], dtype='int64')\n",
      "review for entire anne series \n",
      " the eight book anne of green gables series by l m montgomery published from 19081939 and read in the grosset  dunlap illustrated junior library version anne of green gables signet classic anne of avonlea and bantam classic all the rest \n",
      " there is no avoiding disclosing that i already love these books i read them at least once a year and have for several years when i got to this years hankering for reading through the series i went ahead and moved them up on the read 1000 list anne of green gables is securely on that list and not by my own recommendation so were all good there i just expanded out to the whole series and made some new observations as i went along \n",
      " now these books are highly revered by many many people in fact prince edward islandwhere the author spent some of her life and where anne takes placeis a tourist haven for anne fans and they come in droves to charter planes and experience the anne museum the anne tours the anne gift shops and savor a bit of the beautiful idyllic scenery that breathes through the anne books i wanted to take my honeymoon there but we were unable to afford it especially compared with the free stay in an everglades condo that came offered as a wedding gift but i still plan on going sometime my husband is well aware of this its like harry potter for romantics you can easily score anne of green gables embroidered pillows lithographs costumes or even soda not to mention the musical \n",
      " l m montgomery lucy maud lived in the late 1800s and early 1900s around the east end of canada she wrote prolifically as a novelist and also for periodicals back when they carried fiction on a regular basis many of her short stories are collected in books and her twenty novels are still in publication including three other shorter series for emily pat and the story girl her writing was popular in its time beginning with publications of short stories upwards of twenty per year but nothing could or would surpass the love and respect for her very first novel anne of green gables \n",
      " anne is a bit feminine for most men or even boys to read it is also a little flowery and descriptive for the modern reader and perhaps even a little short for its genre by modern standards but what makes it so popular i can think of no better reason than to say that anne is a book of complete escapism and where it takes the reader is not only or was not only a real place but also one that is wholesome and hopeful it hearkens back to simpler times to a society with clear morals and small interactions of looking to the future with optimism and adventure and living in the present with hard work and a noble outlook who wouldnt want to go there every once in awhile as i always say i not only enjoy the books but when i am done reading them i know what kind of person i want to grow up to be \n",
      " the story is pretty straightforward anne is an orphan who has been handled roughly details dealt with tactfully over her first ten years and is accidentally adopted by a brother and sister in the backwoods small town of avonlea prince edward island canada anne is overly imaginative and accidentprone but also just a good soul and full of positivity her pride pits her against her faith and that is the struggle that we see unfolding in her relationships including her relationship with classmate gilbert blythe she grows up faces various hardships and bends in the road and becomes a woman with a family of her own in the later books \n",
      " also note that the book is considered childrens literature my aunt gave me this book for my eleventh birthday but i found it too slow and descriptive at the time i read it through for the first time when i was fifteen i have loved it ever since then and can fully appreciate it as an adult if you can get your younger reader through the first couple chapters they too might fall in love with annes scrapes and antics her imagination and spirit she is after all eleven years old \n",
      " at fifteen i quickly acquired the rest of the anne series read it all and then bought every montgomery book that they had in the bookstores remember those days before internet stores i am never disappointed with montgomery although some of her books are better than others as for the anne series i think the first and the last books anne of green gables and rilla of ingleside are the best with the fourth anne of windy poplars being my least favorite i think because of the epistolary form of course we need all those books because we want so desperately to see how anne and gilbertone of the classic loves of all literatureturn out next up i would recommend the three book emily trilogy \n",
      " i dont have much else to say about anne of green gables or the series like anything overlyliterary i would highly recommend it to young girls up to fullgrown women or for family story time once you get through rachel lyndes sitting and watching things pick up and montgomerys anecdotes are sometimes funny sometimes exasperating sometimes heartwrenching but they always come with a little of marillas characteristic dose of moral and annes heavyhanded does of humanity \n",
      " one disclaimer according to the times there are some nonpc moments in these books if i remember correctly they are almost all directed toward french immigrants \n",
      " ive also heard there are some great tv productions and movies of the anne series or based on montgomerys writing about avonlea i can not however do you the service of screening them for you i am rather stubborn on this point anne is so solidified in my own mind that it would disturb me greatly to see an actress in the role and the other characters as well i dont need the movies i have the books but you may want to give them a try i have seen some of the animated series on pbs it doesnt mess with my sense of peace it is acceptable but nothing too notable the 1980s movies anne of green gables and anne of avonlea are i believe the most beloved \n",
      " ill limit my quotes to the first three books which by the way were not the first three written or published the series was written and published quite out of order and was i believe determined partly by fan request \n",
      " anne of green gables \n",
      " and as for the risk theres risks in pretty much everything a body does in the world theres risks in peoples having children of their own if it comes to thatthey dont always turn out well p15 \n",
      " a mere man must have some vent for his emotions p40 \n",
      " youre both queer enough if thats what you mean by kindred spirits p47 \n",
      " if you must borrow trouble for pitys sake borrow it handier home p153 \n",
      " all things great are wound up with all things little p176 \n",
      " oh of course hes good agreed anne but he doesnt seem to get any comfort out of it if i could be good id dance and sing all day because i was glad of it p216 \n",
      " the trouble with you anne is that youre thinking too much about yourself you should just think of mrs allan and what would be nicest and most agreeable to her p226 \n",
      " a little appreciation sometimes does quite as much good as all the conscientious bringing up in the world p243 \n",
      " anne of avonlea \n",
      " it takes all sorts of people to make a world as ive often heard but i think there are some who could be spared p125 \n",
      " not failure but low aim is a crime p131 to quote james russell lowell \n",
      " and i think the violets are little snips of the sky that fell down when the angels cut holes for the stars to shine through and the buttercups are made out of old sunshine and i think the sweet peas will be butterflies when they go to heaven p166 \n",
      " you cant like different people the same way p167 \n",
      " id like kerrenhappuch if it happened to be your name i think people make their names nice or ugly just by what they are themselves p191 \n",
      " at seventeen dreams do satisfy you because you think the realities are awaiting you further on p199 \n",
      " every really beautiful thought was religious no matter what it was about or what day it was thought on p240 \n",
      " id rather look like you than be pretty p243 \n",
      " changes aint totally pleasant but theyre excellent things p266 \n",
      " in this world youve just got to hope for the best and prepare for the worst and take whatever god sends p268 \n",
      " im glad to be a woman with a garden and a work and a sorrow p276 \n",
      " anne of the island \n",
      " it is never nice to have our old shrines desecrated even when we have outgrown them p2 \n",
      " we musnt let next week rob us of this weeks joy p3 \n",
      " i fancy its the unexpected things that give spice to life p4 \n",
      " as phil said it was the difference between being born and being made p48 \n",
      " the life of heaven must be begun here on earth p108 \n",
      " new shoes are smarter than old ones but the old ones are more comfortable p123 \n",
      " never mind thank goodness air and salvation are still free p126 \n",
      " what is to be will be said mrs rachel gloomily and what isnt to be sometimes happens p178 \n",
      " she felt very old and mature and wisewhich showed how young she was p182 \n",
      " review written for the starving artist blog\n"
     ]
    }
   ],
   "source": [
    "def get_cos_sim_rev(doc_tfidf):\n",
    "  return cos_sim(doc_tfidf, X_q5.iloc[0])\n",
    "X_q6 = X_q5.iloc[1:].apply(get_cos_sim_rev, axis=1)\n",
    "top_index = X_q6[max(X_q6) == X_q6].index\n",
    "print(max(X_q6))\n",
    "print(top_index)\n",
    "print(review_text[top_index].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RKqA-v4lQk3G"
   },
   "outputs": [],
   "source": [
    "del X_q5\n",
    "del X_q6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tRSxC-SPrWKJ"
   },
   "source": [
    "Answer for Q6:\n",
    "\n",
    "cosine similarity: 0.9984838370882461\n",
    "\n",
    "Row Index: 1595\n",
    "\n",
    "Text:\n",
    "\n",
    "review for entire anne series \n",
    " the eight book anne of green gables series by l m montgomery published from 19081939 and read in the grosset  dunlap illustrated junior library version anne of green gables signet classic anne of avonlea and bantam classic all the rest \n",
    " there is no avoiding disclosing that i already love these books i read them at least once a year and have for several years when i got to this years hankering for reading through the series i went ahead and moved them up on the read 1000 list anne of green gables is securely on that list and not by my own recommendation so were all good there i just expanded out to the whole series and made some new observations as i went along \n",
    " now these books are highly revered by many many people in fact prince edward islandwhere the author spent some of her life and where anne takes placeis a tourist haven for anne fans and they come in droves to charter planes and experience the anne museum the anne tours the anne gift shops and savor a bit of the beautiful idyllic scenery that breathes through the anne books i wanted to take my honeymoon there but we were unable to afford it especially compared with the free stay in an everglades condo that came offered as a wedding gift but i still plan on going sometime my husband is well aware of this its like harry potter for romantics you can easily score anne of green gables embroidered pillows lithographs costumes or even soda not to mention the musical \n",
    " l m montgomery lucy maud lived in the late 1800s and early 1900s around the east end of canada she wrote prolifically as a novelist and also for periodicals back when they carried fiction on a regular basis many of her short stories are collected in books and her twenty novels are still in publication including three other shorter series for emily pat and the story girl her writing was popular in its time beginning with publications of short stories upwards of twenty per year but nothing could or would surpass the love and respect for her very first novel anne of green gables \n",
    " anne is a bit feminine for most men or even boys to read it is also a little flowery and descriptive for the modern reader and perhaps even a little short for its genre by modern standards but what makes it so popular i can think of no better reason than to say that anne is a book of complete escapism and where it takes the reader is not only or was not only a real place but also one that is wholesome and hopeful it hearkens back to simpler times to a society with clear morals and small interactions of looking to the future with optimism and adventure and living in the present with hard work and a noble outlook who wouldnt want to go there every once in awhile as i always say i not only enjoy the books but when i am done reading them i know what kind of person i want to grow up to be \n",
    " the story is pretty straightforward anne is an orphan who has been handled roughly details dealt with tactfully over her first ten years and is accidentally adopted by a brother and sister in the backwoods small town of avonlea prince edward island canada anne is overly imaginative and accidentprone but also just a good soul and full of positivity her pride pits her against her faith and that is the struggle that we see unfolding in her relationships including her relationship with classmate gilbert blythe she grows up faces various hardships and bends in the road and becomes a woman with a family of her own in the later books \n",
    " also note that the book is considered childrens literature my aunt gave me this book for my eleventh birthday but i found it too slow and descriptive at the time i read it through for the first time when i was fifteen i have loved it ever since then and can fully appreciate it as an adult if you can get your younger reader through the first couple chapters they too might fall in love with annes scrapes and antics her imagination and spirit she is after all eleven years old \n",
    " at fifteen i quickly acquired the rest of the anne series read it all and then bought every montgomery book that they had in the bookstores remember those days before internet stores i am never disappointed with montgomery although some of her books are better than others as for the anne series i think the first and the last books anne of green gables and rilla of ingleside are the best with the fourth anne of windy poplars being my least favorite i think because of the epistolary form of course we need all those books because we want so desperately to see how anne and gilbertone of the classic loves of all literatureturn out next up i would recommend the three book emily trilogy \n",
    " i dont have much else to say about anne of green gables or the series like anything overlyliterary i would highly recommend it to young girls up to fullgrown women or for family story time once you get through rachel lyndes sitting and watching things pick up and montgomerys anecdotes are sometimes funny sometimes exasperating sometimes heartwrenching but they always come with a little of marillas characteristic dose of moral and annes heavyhanded does of humanity \n",
    " one disclaimer according to the times there are some nonpc moments in these books if i remember correctly they are almost all directed toward french immigrants \n",
    " ive also heard there are some great tv productions and movies of the anne series or based on montgomerys writing about avonlea i can not however do you the service of screening them for you i am rather stubborn on this point anne is so solidified in my own mind that it would disturb me greatly to see an actress in the role and the other characters as well i dont need the movies i have the books but you may want to give them a try i have seen some of the animated series on pbs it doesnt mess with my sense of peace it is acceptable but nothing too notable the 1980s movies anne of green gables and anne of avonlea are i believe the most beloved \n",
    " ill limit my quotes to the first three books which by the way were not the first three written or published the series was written and published quite out of order and was i believe determined partly by fan request \n",
    " anne of green gables \n",
    " and as for the risk theres risks in pretty much everything a body does in the world theres risks in peoples having children of their own if it comes to thatthey dont always turn out well p15 \n",
    " a mere man must have some vent for his emotions p40 \n",
    " youre both queer enough if thats what you mean by kindred spirits p47 \n",
    " if you must borrow trouble for pitys sake borrow it handier home p153 \n",
    " all things great are wound up with all things little p176 \n",
    " oh of course hes good agreed anne but he doesnt seem to get any comfort out of it if i could be good id dance and sing all day because i was glad of it p216 \n",
    " the trouble with you anne is that youre thinking too much about yourself you should just think of mrs allan and what would be nicest and most agreeable to her p226 \n",
    " a little appreciation sometimes does quite as much good as all the conscientious bringing up in the world p243 \n",
    " anne of avonlea \n",
    " it takes all sorts of people to make a world as ive often heard but i think there are some who could be spared p125 \n",
    " not failure but low aim is a crime p131 to quote james russell lowell \n",
    " and i think the violets are little snips of the sky that fell down when the angels cut holes for the stars to shine through and the buttercups are made out of old sunshine and i think the sweet peas will be butterflies when they go to heaven p166 \n",
    " you cant like different people the same way p167 \n",
    " id like kerrenhappuch if it happened to be your name i think people make their names nice or ugly just by what they are themselves p191 \n",
    " at seventeen dreams do satisfy you because you think the realities are awaiting you further on p199 \n",
    " every really beautiful thought was religious no matter what it was about or what day it was thought on p240 \n",
    " id rather look like you than be pretty p243 \n",
    " changes aint totally pleasant but theyre excellent things p266 \n",
    " in this world youve just got to hope for the best and prepare for the worst and take whatever god sends p268 \n",
    " im glad to be a woman with a garden and a work and a sorrow p276 \n",
    " anne of the island \n",
    " it is never nice to have our old shrines desecrated even when we have outgrown them p2 \n",
    " we musnt let next week rob us of this weeks joy p3 \n",
    " i fancy its the unexpected things that give spice to life p4 \n",
    " as phil said it was the difference between being born and being made p48 \n",
    " the life of heaven must be begun here on earth p108 \n",
    " new shoes are smarter than old ones but the old ones are more comfortable p123 \n",
    " never mind thank goodness air and salvation are still free p126 \n",
    " what is to be will be said mrs rachel gloomily and what isnt to be sometimes happens p178 \n",
    " she felt very old and mature and wisewhich showed how young she was p182 \n",
    " review written for the starving artist blog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3WsoAFZOuo35"
   },
   "source": [
    "# Q7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D5fdx5f6skuP"
   },
   "outputs": [],
   "source": [
    "q7_df = df.sample(30000, random_state=1)\n",
    "q7_review_text = q7_df['review_text'].apply(lambda doc: doc.lower())\n",
    "# re.sub('[%s]' % re.escape(string.punctuation), '', doc.lower()) \n",
    "train_X = q7_review_text.iloc[:10000]\n",
    "val_X = q7_review_text.iloc[10000:20000]\n",
    "test_X = q7_review_text.iloc[20000:]\n",
    "y_train = q7_df['rating'].iloc[:10000]\n",
    "y_val = q7_df['rating'].iloc[10000:20000]\n",
    "y_test = q7_df['rating'].iloc[20000:]\n",
    "\n",
    "del q7_df\n",
    "del q7_review_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2873
    },
    "colab_type": "code",
    "id": "qMnIy-5ZaoQZ",
    "outputId": "94247668-ba1c-4508-8dec-5176e4b2892a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C_val: 0.01\n",
      "MSE for val: [1.1717382]\n",
      "MSE for test: [1.11666483]\n",
      "C_val: 0.1\n",
      "MSE for val: [1.14395191]\n",
      "MSE for test: [1.08917372]\n",
      "C_val: 1\n",
      "MSE for val: [1.27955671]\n",
      "MSE for test: [1.22557528]\n",
      "C_val: 10\n",
      "MSE for val: [1.38729721]\n",
      "MSE for test: [1.33641664]\n",
      "C_val: 100\n",
      "MSE for val: [1.40531231]\n",
      "MSE for test: [1.35751494]\n",
      "------------------------------------------------------------------\n",
      "uni True True\n",
      "TOP C_val: 0.1\n",
      "TOP MSE for val: [1.14395191]\n",
      "TOP MSE for test: [1.08917372]\n",
      "------------------------------------------------------------------\n",
      "C_val: 0.01\n",
      "MSE for val: [1.30788342]\n",
      "MSE for test: [1.23206033]\n",
      "C_val: 0.1\n",
      "MSE for val: [1.30776975]\n",
      "MSE for test: [1.23195853]\n",
      "C_val: 1\n",
      "MSE for val: [1.30664442]\n",
      "MSE for test: [1.23095109]\n",
      "C_val: 10\n",
      "MSE for val: [1.29643232]\n",
      "MSE for test: [1.2218377]\n",
      "C_val: 100\n",
      "MSE for val: [1.24880882]\n",
      "MSE for test: [1.1803991]\n",
      "------------------------------------------------------------------\n",
      "uni True False\n",
      "TOP C_val: 100\n",
      "TOP MSE for val: [1.24880882]\n",
      "TOP MSE for test: [1.1803991]\n",
      "------------------------------------------------------------------\n",
      "C_val: 0.01\n",
      "MSE for val: [1.18537755]\n",
      "MSE for test: [1.13618925]\n",
      "C_val: 0.1\n",
      "MSE for val: [1.14443482]\n",
      "MSE for test: [1.09007059]\n",
      "C_val: 1\n",
      "MSE for val: [1.26921161]\n",
      "MSE for test: [1.21401963]\n",
      "C_val: 10\n",
      "MSE for val: [1.38593792]\n",
      "MSE for test: [1.33513887]\n",
      "C_val: 100\n",
      "MSE for val: [1.40520821]\n",
      "MSE for test: [1.35743579]\n",
      "------------------------------------------------------------------\n",
      "uni False True\n",
      "TOP C_val: 0.1\n",
      "TOP MSE for val: [1.14443482]\n",
      "TOP MSE for test: [1.09007059]\n",
      "------------------------------------------------------------------\n",
      "C_val: 0.01\n",
      "MSE for val: [1.30337386]\n",
      "MSE for test: [1.2353775]\n",
      "C_val: 0.1\n",
      "MSE for val: [1.30325288]\n",
      "MSE for test: [1.23526273]\n",
      "C_val: 1\n",
      "MSE for val: [1.30205563]\n",
      "MSE for test: [1.23412712]\n",
      "C_val: 10\n",
      "MSE for val: [1.29123373]\n",
      "MSE for test: [1.22386857]\n",
      "C_val: 100\n",
      "MSE for val: [1.24213204]\n",
      "MSE for test: [1.17728611]\n",
      "------------------------------------------------------------------\n",
      "uni False False\n",
      "TOP C_val: 100\n",
      "TOP MSE for val: [1.24213204]\n",
      "TOP MSE for test: [1.17728611]\n",
      "------------------------------------------------------------------\n",
      "C_val: 0.01\n",
      "MSE for val: [1.23882899]\n",
      "MSE for test: [1.1847323]\n",
      "C_val: 0.1\n",
      "MSE for val: [1.20983936]\n",
      "MSE for test: [1.15273147]\n",
      "C_val: 1\n",
      "MSE for val: [1.31449057]\n",
      "MSE for test: [1.26269763]\n",
      "C_val: 10\n",
      "MSE for val: [1.39327617]\n",
      "MSE for test: [1.34288029]\n",
      "C_val: 100\n",
      "MSE for val: [1.40599217]\n",
      "MSE for test: [1.3582398]\n",
      "------------------------------------------------------------------\n",
      "bi True True\n",
      "TOP C_val: 0.1\n",
      "TOP MSE for val: [1.20983936]\n",
      "TOP MSE for test: [1.15273147]\n",
      "------------------------------------------------------------------\n",
      "C_val: 0.01\n",
      "MSE for val: [1.29346099]\n",
      "MSE for test: [1.25151887]\n",
      "C_val: 0.1\n",
      "MSE for val: [1.29328648]\n",
      "MSE for test: [1.25135752]\n",
      "C_val: 1\n",
      "MSE for val: [1.29160366]\n",
      "MSE for test: [1.24977885]\n",
      "C_val: 10\n",
      "MSE for val: [1.27790243]\n",
      "MSE for test: [1.23624857]\n",
      "C_val: 100\n",
      "MSE for val: [1.22747573]\n",
      "MSE for test: [1.18457336]\n",
      "------------------------------------------------------------------\n",
      "bi True False\n",
      "TOP C_val: 100\n",
      "TOP MSE for val: [1.22747573]\n",
      "TOP MSE for test: [1.18457336]\n",
      "------------------------------------------------------------------\n",
      "C_val: 0.01\n",
      "MSE for val: [1.27783659]\n",
      "MSE for test: [1.20743138]\n",
      "C_val: 0.1\n",
      "MSE for val: [1.23029259]\n",
      "MSE for test: [1.1690808]\n",
      "C_val: 1\n",
      "MSE for val: [1.31946977]\n",
      "MSE for test: [1.26569813]\n",
      "C_val: 10\n",
      "MSE for val: [1.39469968]\n",
      "MSE for test: [1.34437468]\n",
      "C_val: 100\n",
      "MSE for val: [1.40615437]\n",
      "MSE for test: [1.35844793]\n",
      "------------------------------------------------------------------\n",
      "bi False True\n",
      "TOP C_val: 0.1\n",
      "TOP MSE for val: [1.23029259]\n",
      "TOP MSE for test: [1.1690808]\n",
      "------------------------------------------------------------------\n",
      "C_val: 0.01\n",
      "MSE for val: [1.29755969]\n",
      "MSE for test: [1.23678497]\n",
      "C_val: 0.1\n",
      "MSE for val: [1.29736702]\n",
      "MSE for test: [1.23660087]\n",
      "C_val: 1\n",
      "MSE for val: [1.29548437]\n",
      "MSE for test: [1.23479922]\n",
      "C_val: 10\n",
      "MSE for val: [1.27990291]\n",
      "MSE for test: [1.2198374]\n",
      "C_val: 100\n",
      "MSE for val: [1.22952891]\n",
      "MSE for test: [1.17268393]\n",
      "------------------------------------------------------------------\n",
      "bi False False\n",
      "TOP C_val: 100\n",
      "TOP MSE for val: [1.22952891]\n",
      "TOP MSE for test: [1.17268393]\n",
      "------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "curr_gram_dict = {}\n",
    "curr_gram_spec = 'bi'\n",
    "keep_punc = True\n",
    "curr_tfidf = True\n",
    "\n",
    "curr_gram_idf_dict = {}\n",
    "curr_gram_index_dict = {}\n",
    "\n",
    "def curr_pref_list(doc):\n",
    "  if keep_punc:\n",
    "    token = re.findall(r\"[\\w]+|['.,<>?\\/#!$%\\^&\\*;:{}\\[\\]=+\\-_`~()\\\"]\",\n",
    "                       doc)\n",
    "  else:\n",
    "    doc = re.sub('[%s]' % re.escape(string.punctuation), '', doc)\n",
    "    token = word_tokenize(doc)\n",
    "  if curr_gram_spec == 'uni':\n",
    "    curr_pref_list = token\n",
    "  else:\n",
    "    curr_pref_list = list(ngrams(token, 2))\n",
    "  return curr_pref_list\n",
    "\n",
    "def save_curr_grams(curr_X):\n",
    "  def save_curr_grams_(doc):\n",
    "    global curr_gram_dict\n",
    "\n",
    "    curr_gram_list = curr_pref_list(doc)\n",
    "    for curr_gram in curr_gram_list:\n",
    "      if curr_gram not in curr_gram_dict:\n",
    "        curr_gram_dict[curr_gram] = 0\n",
    "      curr_gram_dict[curr_gram] += 1\n",
    "    return doc\n",
    "  return curr_X.apply(save_curr_grams_)\n",
    "\n",
    "def save_curr_idf(curr_X):\n",
    "  global curr_gram_dict\n",
    "  global curr_gram_index_dict\n",
    "  global curr_gram_idf_dict\n",
    "\n",
    "  curr_freq_list = [(k, v) for k, v in curr_gram_dict.items()]\n",
    "  curr_freq_list.sort(key=lambda x: x[1], reverse=True)\n",
    "  top_1000_grams = [curr_gram_pair[0] for curr_gram_pair in curr_freq_list[:1000]]\n",
    "  curr_gram_index_dict = {curr_gram: i for i, curr_gram in enumerate(top_1000_grams)}\n",
    "  if curr_tfidf:\n",
    "    curr_gram_idf_dict = {curr_gram: 0 for curr_gram in top_1000_grams}\n",
    "  else:\n",
    "    return curr_X\n",
    "  def save_curr_idf_(doc):\n",
    "    global curr_gram_idf_dict\n",
    "\n",
    "    curr_gram_set = set(curr_pref_list(doc))\n",
    "    for curr_gram in curr_gram_set:\n",
    "      if curr_gram in curr_gram_idf_dict:\n",
    "        curr_gram_idf_dict[curr_gram] += 1\n",
    "    return doc\n",
    "  return curr_X.apply(save_curr_idf_)\n",
    "\n",
    "def top_1000_feat(curr_X):\n",
    "  def top_1000_feat_(doc):\n",
    "    global curr_gram_index_dict\n",
    "    global curr_gram_idf_dict\n",
    "\n",
    "    curr_gram_list = curr_pref_list(doc)\n",
    "    curr_top_feat = [0] * 1000\n",
    "    for curr_gram in curr_gram_list:\n",
    "      if curr_gram in curr_gram_index_dict:\n",
    "        curr_top_feat[curr_gram_index_dict[curr_gram]] += 1\n",
    "    if not curr_tfidf:\n",
    "      curr_top_feat.append(1)\n",
    "      return pd.Series(curr_top_feat)\n",
    "    for curr_gram in set(curr_gram_list):\n",
    "      if curr_gram in curr_gram_index_dict:\n",
    "        curr_top_feat[curr_gram_index_dict[curr_gram]] /= len(curr_gram_list)\n",
    "        curr_top_feat[curr_gram_index_dict[curr_gram]] *=\\\n",
    "          math.log(train_X.shape[0] / curr_gram_idf_dict[curr_gram],\n",
    "                    10)\n",
    "    curr_top_feat.append(1)\n",
    "    return pd.Series(curr_top_feat)\n",
    "  return curr_X.apply(top_1000_feat_)\n",
    "\n",
    "preprocessor = Pipeline(steps=[\n",
    "        ('gram', FunctionTransformer(save_curr_grams,\n",
    "                            validate=False)),\n",
    "        ('idf', FunctionTransformer(save_curr_idf,\n",
    "                            validate=False)),\n",
    "        ('top_feat', FunctionTransformer(top_1000_feat,\n",
    "                            validate=False))])\n",
    "\n",
    "top_scores = [[0, math.inf, 0] for j in range(8)]\n",
    "curr_score = 0\n",
    "prev_curr_gram_index_dict = {}\n",
    "prev_curr_gram_idf_dict = {}\n",
    "for curr_gram_spec in ['uni', 'bi']:\n",
    "  for keep_punc in [True, False]:\n",
    "    for curr_tfidf in [True, False]:\n",
    "      curr_gram_dict = {}\n",
    "      curr_gram_idf_dict = {}\n",
    "      curr_gram_index_dict = {}\n",
    "\n",
    "      prep_train_X = preprocessor.transform(train_X)\n",
    "      prep_val_X = top_1000_feat(val_X)\n",
    "      prep_test_X = top_1000_feat(test_X)\n",
    "\n",
    "      for C_val in [0.01, 0.1, 1, 10, 100]:\n",
    "        clf = Pipeline(steps=[\n",
    "                # ('preprocessor', preprocessor),\n",
    "                ('logistic', linear_model.Ridge(C_val, fit_intercept=False)),\n",
    "        ])\n",
    "        clf.fit(prep_train_X, y_train)\n",
    "        \n",
    "        theta = clf.named_steps['logistic'].coef_\n",
    "\n",
    "        print('C_val:', C_val)\n",
    "        print('MSE for val:', MSE(prep_val_X, theta, y_val))\n",
    "        print('MSE for test:', MSE(prep_test_X, theta, y_test))\n",
    "\n",
    "        if top_scores[curr_score][1] > MSE(prep_val_X, theta, y_val):\n",
    "          top_scores[curr_score][0] = C_val\n",
    "          top_scores[curr_score][1] = MSE(prep_val_X, theta, y_val)\n",
    "          top_scores[curr_score][2] = MSE(prep_test_X, theta, y_test)\n",
    "      \n",
    "      print('------------------------------------------------------------------')\n",
    "      print(curr_gram_spec, keep_punc, curr_tfidf)\n",
    "      print('TOP C_val:', top_scores[curr_score][0])\n",
    "      print('TOP MSE for val:', top_scores[curr_score][1])\n",
    "      print('TOP MSE for test:', top_scores[curr_score][2])\n",
    "      print('------------------------------------------------------------------')\n",
    "      curr_score += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "id": "k9RtFuO2d5uU",
    "outputId": "ae9b60c6-1422-41ad-ff38-b8e7cb20cec8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unigram v.s. Bigram</th>\n",
       "      <th>Preserve v.s. Remove Punctuation</th>\n",
       "      <th>TFIDF v.s. Word Counts</th>\n",
       "      <th>Regularization Parameter</th>\n",
       "      <th>MSE on Validation</th>\n",
       "      <th>MSE on Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unigram</td>\n",
       "      <td>Preserve</td>\n",
       "      <td>TFIDF</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[1.1439519082131546]</td>\n",
       "      <td>[1.0891737182200811]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Unigram</td>\n",
       "      <td>Preserve</td>\n",
       "      <td>Word Count</td>\n",
       "      <td>100.0</td>\n",
       "      <td>[1.2488088239460031]</td>\n",
       "      <td>[1.180399104569241]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Unigram</td>\n",
       "      <td>Remove</td>\n",
       "      <td>TFIDF</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[1.1444348196780214]</td>\n",
       "      <td>[1.0900705908180979]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Unigram</td>\n",
       "      <td>Remove</td>\n",
       "      <td>Word Count</td>\n",
       "      <td>100.0</td>\n",
       "      <td>[1.2421320381073877]</td>\n",
       "      <td>[1.1772861075892005]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bigram</td>\n",
       "      <td>Preserve</td>\n",
       "      <td>TFIDF</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[1.2098393631698006]</td>\n",
       "      <td>[1.1527314712509042]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bigram</td>\n",
       "      <td>Preserve</td>\n",
       "      <td>Word Count</td>\n",
       "      <td>100.0</td>\n",
       "      <td>[1.2274757253057103]</td>\n",
       "      <td>[1.1845733604836595]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bigram</td>\n",
       "      <td>Remove</td>\n",
       "      <td>TFIDF</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[1.2302925879632027]</td>\n",
       "      <td>[1.169080802677434]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bigram</td>\n",
       "      <td>Remove</td>\n",
       "      <td>Word Count</td>\n",
       "      <td>100.0</td>\n",
       "      <td>[1.2295289082311316]</td>\n",
       "      <td>[1.1726839259931665]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unigram v.s. Bigram  ...           MSE on Test\n",
       "0             Unigram  ...  [1.0891737182200811]\n",
       "1             Unigram  ...   [1.180399104569241]\n",
       "2             Unigram  ...  [1.0900705908180979]\n",
       "3             Unigram  ...  [1.1772861075892005]\n",
       "4              Bigram  ...  [1.1527314712509042]\n",
       "5              Bigram  ...  [1.1845733604836595]\n",
       "6              Bigram  ...   [1.169080802677434]\n",
       "7              Bigram  ...  [1.1726839259931665]\n",
       "\n",
       "[8 rows x 6 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# curr_score = 0\n",
    "# for col_a in ['Unigram', 'Bigram']:\n",
    "#   for col_b in ['Preserve', 'Remove']:\n",
    "#     for col_c in ['TFIDF', 'Word Count']:\n",
    "#       top_scores[curr_score] = [col_a, col_b, col_c] + top_scores[curr_score]\n",
    "#       curr_score += 1\n",
    "pd.DataFrame(top_scores,\n",
    "             columns=['Unigram v.s. Bigram',\n",
    "                      'Preserve v.s. Remove Punctuation',\n",
    "                      'TFIDF v.s. Word Counts',\n",
    "                      'Regularization Parameter',\n",
    "                      'MSE on Validation',\n",
    "                      'MSE on Test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iFT1InCKyyLF"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Untitled8.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
